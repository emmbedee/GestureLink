Gesture Link Implementation Milestone Summary:

Milestone 1: Initial research for technical solutions and framework functions were written out in Python.  The idea was to write a rough draft to begin the code structure and understand what individual functions/methods/classes need to exist. 

Milestone 2: More paper prototyping for the GUI and some framework functions were expanded/filled out.  This was the first "working" bit of code, however it was not practically functional.  

Milestone 3: A functional prototype was working with a basic GUI.  This is where the recognition functions all worked as initially proposed and only need to be fleshed out and polished.  

Milestone 4: Working from Milestone 3 and utilizing user feedback, the app is now what I would confidently call a "minimum viable product."  Meaning, as it currently stands, this is a working application that can be easily deployed to most people's desktop computing systems.  User feedback was successfully and extensively integrated and the design of the GUI reflects these changes.  





#########################################################################################################################################





# GestureLink
Title: 
Gesture Link: Webcam-Driven Augmentation for HCI

1.	Topic Description:
Gesture Link is a project aimed at augmenting Human-Computer Interaction (HCI) through the implementation of gesture recognition technology, utilizing webcams. Developed with Python, this project seeks to create an accessible, inclusive, and user-friendly interface that enables intuitive interaction with computers, surpassing the limitations of traditional input devices like keyboards, mice, and touchscreens.  Ideally, the “first pass” version of this would, via gesture recognition: launch desktop apps, adjust volume, “show” the desktop by minimizing all windows, etc.  

2.	Technology: 

Proof of Concept specifications:

•	Application-focused.
•	Gesture recognition: implemented via Python.
•	Webcam integration: chosen due to its widespread availability. 
•	Operating System target: Windows 10/11.

3.	Potential Features:

•	Volume up/down and mute/unmute function.
•	Media playback: play, pause, etc.
•	Launch application (predetermined within the app).
•	System shutdown/restart commands.
•	Mode toggle: battery saver mode or focus mode. 
•	Show desktop.
•	Open specific webpage (acts much like launch application).
•	Change screen brightness levels or toggle nighttime mode. 
•	Scrolling and navigation: enable users to scroll through pages or navigate through sections via gesture. 
•	Zoom in/out: change the font size on the fly via Windows API.
•	Switch between applications: essentially an Alt-Tab alternative.
•	Cursor movement/clicking.
•	Gesture customization: pick which specific hand shapes do what. 

4.	Team Organization:

Documentation: Jadon Onstead, Ephraim Collins
Implementation: Emm Doeden, Jadon Onstead
Video:  Ephraim Collins, Emm Doeden

Since this team is comparatively small, this gives us a big advantage to be able to be as agile as possible.  So, while the above description is accurate, we will be able to help each other with everything, and the above declarations are mostly a formality.  
