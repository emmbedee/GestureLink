# GestureLink
Title: 
Gesture Link: Webcam-Driven Augmentation for HCI

1.	Topic Description:
Gesture Link is a project aimed at augmenting Human-Computer Interaction (HCI) through the implementation of gesture recognition technology, utilizing webcams. Developed with Python, this project seeks to create an accessible, inclusive, and user-friendly interface that enables intuitive interaction with computers, surpassing the limitations of traditional input devices like keyboards, mice, and touchscreens.  Ideally, the “first pass” version of this would, via gesture recognition: launch desktop apps, adjust volume, “show” the desktop by minimizing all windows, etc.  

2.	Technology: 

Proof of Concept specifications:

•	Application-focused.
•	Gesture recognition: implemented via Python.
•	Webcam integration: chosen due to its widespread availability. 
•	Operating System target: Windows 10/11.

3.	Potential Features:

•	Volume up/down and mute/unmute function.
•	Media playback: play, pause, etc.
•	Launch application (predetermined within the app).
•	System shutdown/restart commands.
•	Mode toggle: battery saver mode or focus mode. 
•	Show desktop.
•	Open specific webpage (acts much like launch application).
•	Change screen brightness levels or toggle nighttime mode. 
•	Scrolling and navigation: enable users to scroll through pages or navigate through sections via gesture. 
•	Zoom in/out: change the font size on the fly via Windows API.
•	Switch between applications: essentially an Alt-Tab alternative.
•	Cursor movement/clicking.
•	Gesture customization: pick which specific hand shapes do what. 

4.	Team Organization:

Documentation: Jadon Onstead, Ephraim Collins
Implementation: Emm Doeden, Jadon Onstead
Video:  Ephraim Collins, Emm Doeden

Since this team is comparatively small, this gives us a big advantage to be able to be as agile as possible.  So, while the above description is accurate, we will be able to help each other with everything, and the above declarations are mostly a formality.  
